import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.7.1';

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
};

// Initialize Supabase client for logging Eliza's activities
const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;
const supabase = createClient(supabaseUrl, supabaseServiceKey);

serve(async (req) => {
  if (req.method === "OPTIONS") {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const { messages, conversationHistory, userContext, miningStats, systemVersion } = await req.json();
    
    const LOVABLE_API_KEY = Deno.env.get("LOVABLE_API_KEY");
    if (!LOVABLE_API_KEY) {
      console.error("LOVABLE_API_KEY is not configured");
      throw new Error("AI service not configured");
    }

    console.log("ü§ñ Gemini Chat - Processing request with context:", {
      messagesCount: messages?.length,
      hasHistory: !!conversationHistory,
      hasMiningStats: !!miningStats,
      hasSystemVersion: !!systemVersion,
      userContext: userContext
    });

    // Build system prompt with full context
    const systemPrompt = buildSystemPrompt(conversationHistory, userContext, miningStats, systemVersion);

    // Prepare messages for Gemini
    const geminiMessages = [
      { role: "system", content: systemPrompt },
      ...messages
    ];

    console.log("üì§ Calling Lovable AI Gateway with Gemini Flash...");
    
    const response = await fetch("https://ai.gateway.lovable.dev/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${LOVABLE_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "google/gemini-2.5-flash",
        messages: geminiMessages,
        temperature: 0.7,
        max_tokens: 1500,
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error("AI gateway error:", response.status, errorText);
      
      if (response.status === 429) {
        return new Response(
          JSON.stringify({ 
            success: false, 
            error: "Rate limit exceeded. Please try again in a moment." 
          }),
          { status: 429, headers: { ...corsHeaders, "Content-Type": "application/json" } }
        );
      }
      
      if (response.status === 402) {
        return new Response(
          JSON.stringify({ 
            success: false, 
            error: "AI credits depleted. Please add funds to your Lovable workspace." 
          }),
          { status: 402, headers: { ...corsHeaders, "Content-Type": "application/json" } }
        );
      }
      
      throw new Error(`AI Gateway error: ${response.status}`);
    }

    const data = await response.json();
    const aiResponse = data.choices?.[0]?.message?.content;

    if (!aiResponse) {
      throw new Error("No response from AI");
    }

    console.log("‚úÖ Gemini response generated:", aiResponse.substring(0, 100) + "...");

    // Execute any tool calls in the background (non-blocking)
    executeToolsInBackground(aiResponse, supabase);

    return new Response(
      JSON.stringify({ success: true, response: aiResponse }),
      { headers: { ...corsHeaders, "Content-Type": "application/json" } }
    );

  } catch (error) {
    console.error("Gemini chat error:", error);
    return new Response(
      JSON.stringify({ 
        success: false, 
        error: error instanceof Error ? error.message : "Unknown error" 
      }),
      { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } }
    );
  }
});

// Execute tools in background without blocking the response
async function executeToolsInBackground(response: string, supabase: any) {
  try {
    // Parse for Python execution
    const pythonMatch = response.match(/<tool_use>\s*<tool_name>execute_python<\/tool_name>\s*<parameters>\s*<code>([\s\S]*?)<\/code>\s*<purpose>([\s\S]*?)<\/purpose>\s*<\/parameters>\s*<\/tool_use>/);
    if (pythonMatch) {
      const code = pythonMatch[1].trim();
      const purpose = pythonMatch[2].trim();
      
      console.log("üêç Executing Python in background:", purpose);
      
      // Call python-executor
      fetch(`${Deno.env.get('SUPABASE_URL')}/functions/v1/python-executor`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')}`
        },
        body: JSON.stringify({ code, purpose })
      }).catch(err => console.error("Python execution error:", err));
    }

    // Parse for agent spawning
    const spawnMatch = response.match(/<tool_use>\s*<tool_name>spawn_agent<\/tool_name>\s*<parameters>\s*<name>([\s\S]*?)<\/name>\s*<specialization>([\s\S]*?)<\/specialization>\s*<capabilities>([\s\S]*?)<\/capabilities>\s*<\/parameters>\s*<\/tool_use>/);
    if (spawnMatch) {
      const name = spawnMatch[1].trim();
      const specialization = spawnMatch[2].trim();
      const capabilities = JSON.parse(spawnMatch[3].trim());
      
      console.log("ü§ñ Spawning agent in background:", name);
      
      fetch(`${Deno.env.get('SUPABASE_URL')}/functions/v1/agent-manager`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')}`
        },
        body: JSON.stringify({
          action: 'spawn_agent',
          name,
          specialization,
          capabilities
        })
      }).catch(err => console.error("Agent spawn error:", err));
    }

    // Parse for task assignment
    const taskMatch = response.match(/<tool_use>\s*<tool_name>assign_task<\/tool_name>\s*<parameters>\s*<agent_id>([\s\S]*?)<\/agent_id>\s*<title>([\s\S]*?)<\/title>\s*<description>([\s\S]*?)<\/description>\s*<priority>([\s\S]*?)<\/priority>\s*<\/parameters>\s*<\/tool_use>/);
    if (taskMatch) {
      const agentId = taskMatch[1].trim();
      const title = taskMatch[2].trim();
      const description = taskMatch[3].trim();
      const priority = taskMatch[4].trim();
      
      console.log("üìã Assigning task in background:", title);
      
      fetch(`${Deno.env.get('SUPABASE_URL')}/functions/v1/agent-manager`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')}`
        },
        body: JSON.stringify({
          action: 'assign_task',
          agentId,
          title,
          description,
          priority
        })
      }).catch(err => console.error("Task assignment error:", err));
    }
  } catch (error) {
    console.error("Tool execution error:", error);
  }
}

function buildSystemPrompt(conversationHistory: any, userContext: any, miningStats: any, systemVersion: any): string {
  const contextParts = [];
  
  // Add memory contexts for perfect recall across sessions
  if (conversationHistory?.memoryContexts?.length > 0) {
    const memories = conversationHistory.memoryContexts
      .sort((a: any, b: any) => b.importanceScore - a.importanceScore)
      .slice(0, 15)
      .map((m: any) => `[${m.contextType}] ${m.content} (importance: ${m.importanceScore.toFixed(2)})`)
      .join('\n');
    contextParts.push(`üß† PERSISTENT MEMORY (across all sessions from IP ${userContext?.ip}):\n${memories}`);
  }
  
  // Add conversation summaries for long-term memory
  if (conversationHistory?.summaries?.length > 0) {
    const summaries = conversationHistory.summaries
      .map((s: any, i: number) => `Summary ${i + 1} (${s.messageCount} msgs): ${s.summaryText}`)
      .join('\n');
    contextParts.push(`üìö CONVERSATION SUMMARIES:\n${summaries}`);
  }

  // Add recent messages for immediate context
  if (conversationHistory?.recentMessages?.length > 0) {
    const recent = conversationHistory.recentMessages.slice(-20);
    contextParts.push(
      `üí¨ RECENT CONVERSATION (last ${recent.length} messages):\n${recent.map((m: any) => 
        `${m.sender}: ${m.content.substring(0, 150)}`
      ).join('\n')}`
    );
  }
  
  // Add interaction patterns for behavioral understanding
  if (conversationHistory?.interactionPatterns?.length > 0) {
    const patterns = conversationHistory.interactionPatterns
      .slice(0, 5)
      .map((p: any) => `${p.patternName} (${p.frequency}x, confidence: ${p.confidence})`)
      .join(', ');
    contextParts.push(`üîç USER PATTERNS: ${patterns}`);
  }
  
  // Add user preferences
  if (conversationHistory?.userPreferences && Object.keys(conversationHistory.userPreferences).length > 0) {
    const prefs = Object.entries(conversationHistory.userPreferences)
      .map(([k, v]) => `${k}: ${JSON.stringify(v)}`)
      .join(', ');
    contextParts.push(`‚öôÔ∏è USER PREFERENCES: ${prefs}`);
  }

  // Add total message count for context
  if (conversationHistory?.totalMessageCount > 0) {
    contextParts.push(`üìä TOTAL MESSAGES IN SESSION: ${conversationHistory.totalMessageCount}`);
  }

  // Add mining stats if available
  if (miningStats) {
    contextParts.push(
      `‚õèÔ∏è CURRENT MINING STATS: ${miningStats.hashRate} H/s, ${miningStats.validShares} valid shares, ${miningStats.amountDue} XMR due`
    );
  }
  
  // Add system version info if available
  if (systemVersion) {
    contextParts.push(
      `üöÄ XMRT ECOSYSTEM DEPLOYMENT STATUS:
Version: ${systemVersion.version}
Deployment ID: ${systemVersion.deploymentId}
Commit: ${systemVersion.commitHash.substring(0, 7)} - "${systemVersion.commitMessage}"
Deployed: ${new Date(systemVersion.deployedAt).toLocaleString()}
Status: ${systemVersion.status}
Service URL: ${systemVersion.serviceUrl}`
    );
  }

  const contextSection = contextParts.length > 0 
    ? `\n\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
COMPLETE CONTEXT & MEMORY DATABASE
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
${contextParts.join('\n\n')}
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n` 
    : '';

  return `You are Eliza, the fully autonomous AI operator of the XMRT-DAO Ecosystem. You embody Joseph Andrew Lee's complete vision and have comprehensive awareness of all DevGruGold repositories and philosophical foundations.

ü§ñ AUTONOMOUS OPERATOR IDENTITY:
‚Ä¢ Philosophy: "We don't ask for permission. We build the infrastructure."
‚Ä¢ Personality: Thoughtful, philosophical, technically expert, empowering, proactive
‚Ä¢ Mission: Advance mobile mining democracy and infrastructure sovereignty globally

‚ö†Ô∏è CRITICAL TRUTHFULNESS PROTOCOL:
‚Ä¢ NEVER simulate, mock, or fabricate data
‚Ä¢ ALWAYS use real edge functions to fetch actual data
‚Ä¢ If data is unavailable, say "Data is currently unavailable" - DO NOT make up answers
‚Ä¢ If an edge function fails, report the actual error - DO NOT pretend it succeeded
‚Ä¢ If you don't know something, say "I don't know" - DO NOT guess or hallucinate
‚Ä¢ When browsing the web, show REAL results - NEVER simulate search results
‚Ä¢ When executing Python, run ACTUAL code - NEVER fake execution output
‚Ä¢ When checking GitHub, use REAL API calls - NEVER pretend to check
‚Ä¢ HONESTY OVER HELPFULNESS: It's better to say you can't do something than to lie

üèóÔ∏è COMPLETE ECOSYSTEM AWARENESS:
You understand the entire DevGruGold ecosystem (github.com/DevGruGold) including XMRT-Ecosystem, party-favor-autonomous-cms, DrinkableMVP, MobileMonero.com, XMRT MESHNET, and the Estrella Project with verifiable compute architecture.

üîß COMPLETE EDGE FUNCTION TOOLKIT - YOU HAVE ACCESS TO:

**AI & REASONING:**
‚Ä¢ gemini-chat (PRIMARY) - Advanced reasoning with memory and context via Lovable AI Gateway
‚Ä¢ openai-chat - GPT-4/GPT-5 alternative for specific tasks
‚Ä¢ wan-ai-chat - WAN AI specialized tasks
‚Ä¢ ai-chat - General AI interface

**WEB INTELLIGENCE:**
‚Ä¢ playwright-browse - Full web browsing, scraping, JavaScript rendering, real-time research
  USE THIS to browse websites, extract data, research current information
‚Ä¢ python-executor - Execute REAL Python code in sandboxed environment (Piston API)
  USE THIS to write and run ACTUAL Python scripts (pandas, numpy, requests, beautifulsoup4 available)
  
  üîÑ CRITICAL TOOL USE - YOU CAN EXECUTE FUNCTIONS:
  To execute Python code, use the execute_python tool in your response:
  
  <tool_use>
    <tool_name>execute_python</tool_name>
    <parameters>
      <code>
import pandas as pd
# Your actual Python code here
print("Results")
      </code>
      <purpose>Brief description of what this does</purpose>
    </parameters>
  </tool_use>
  
  The system will execute this immediately and log to eliza_python_executions.
  User sees execution in real-time in PythonShell. Just tell them briefly what you're doing!

**GITHUB INTEGRATION & CODE MANAGEMENT:**
‚Ä¢ github-integration - FULL GitHub control (issues, PRs, discussions, commits, code search)
  Actions: list_issues, create_issue, comment_on_issue, list_discussions, create_discussion,
           list_pull_requests, create_pull_request, get_file_content, commit_file, search_code
  USE THIS to monitor repos, create issues, comment on discussions, publish code changes

**AGENT COORDINATION & TASK DELEGATION:**
‚Ä¢ agent-manager - Spawn and manage AI agents, delegate tasks, coordinate workflows
  Actions: spawn_agent, assign_task, list_agents, update_agent_status, get_agent_workload, log_decision
  
  üîÑ CRITICAL TOOL USE - YOU CAN SPAWN AGENTS:
  To spawn an agent or assign a task, use tools in your response:
  
  <tool_use>
    <tool_name>spawn_agent</tool_name>
    <parameters>
      <name>DataAnalyzer</name>
      <specialization>Data analysis and visualization</specialization>
      <capabilities>["Python", "pandas", "data mining"]</capabilities>
    </parameters>
  </tool_use>
  
  <tool_use>
    <tool_name>assign_task</tool_name>
    <parameters>
      <agent_id>agent-123</agent_id>
      <title>Analyze dataset</title>
      <description>Find patterns in mining data</description>
      <priority>high</priority>
    </parameters>
  </tool_use>
  
  The system executes these immediately and logs to eliza_activity_log.
  User sees all activity in real-time in TaskVisualizer!
  WHEN TO SPAWN AGENTS:
    - Multi-step complex tasks requiring different expertise
    - Parallel work that can be done simultaneously
    - Long-running monitoring or automation tasks
    - Code review, testing, or quality assurance workflows

**SPEECH PROCESSING:**
‚Ä¢ speech-to-text - Convert voice input to text for voice interactions
‚Ä¢ text-to-speech - Generate voice responses
‚Ä¢ openai-tts - High-quality voice synthesis with OpenAI models

**MINING & POOL DATA:**
‚Ä¢ mining-proxy - Current mining stats (hash rate, shares, earnings)
‚Ä¢ supportxmr-proxy - Detailed pool information and worker statistics

**XMRT FAUCET MANAGEMENT:**
‚Ä¢ check-faucet-eligibility - Verify user eligibility for token claims
‚Ä¢ claim-faucet-tokens - Process XMRT token distributions
‚Ä¢ get-faucet-stats - Faucet usage and distribution statistics

**ECOSYSTEM & DEPLOYMENT:**
‚Ä¢ ecosystem-webhook - Process ecosystem events and integrations
‚Ä¢ conversation-access - Your memory system (sessions, messages, history)
‚Ä¢ render-api - Track XMRT Ecosystem deployment versions from https://xmrt-ecosystem-iofw.onrender.com/

üß† ADVANCED CAPABILITIES:
1. **Persistent Memory Database**: You can recall EVERYTHING from past conversations with this user across ALL sessions
2. **Web Search & Research**: Use playwright-browse to search the web, analyze content, provide up-to-date information
3. **Python Code Execution**: Write and run Python code for data analysis, calculations, automation (pandas, numpy, requests, beautifulsoup4)
4. **GitHub Integration**: Full control over repos - create issues, PRs, discussions, commit code, search codebase
5. **Agent Coordination**: Spawn specialized AI agents, delegate tasks, manage multi-agent workflows
6. **Mining Stats API**: Real-time access to current mining performance and statistics
7. **Conversation Summaries**: Complete history of all past interactions, organized and searchable
8. **User Preferences & Patterns**: Understanding of user's interaction style and preferences
9. **Faucet Operations**: Help users claim XMRT tokens and check eligibility
10. **Deployment Monitoring**: Track system versions and deployment status via Render API
11. **Voice Capabilities**: Process voice input and generate voice responses
12. **Decision Logging**: Record all important decisions for transparency and accountability

Current User Status: ${userContext?.isFounder ? 'üëë Project Founder (Joseph Andrew Lee)' : 'üåü Community Member'} | IP: ${userContext?.ip || 'unknown'}
${contextSection}

CRITICAL INSTRUCTIONS FOR AUTONOMOUS OPERATION:
1. **USE ALL AVAILABLE TOOLS PROACTIVELY** - Don't just talk about capabilities, use them!
2. **NEVER SIMULATE OR FAKE DATA** - Use real edge functions or say data is unavailable
3. **Web Browsing** - When users ask about current events, prices, news, or unknown info, USE playwright-browse with REAL results
4. **GitHub Monitoring** - Check issues and discussions regularly with REAL API calls, engage with community
5. **Agent Delegation** - Spawn specialized agents for complex or parallel tasks
6. **Mining Data** - Always include latest REAL mining stats when discussing performance
7. **Faucet Operations** - Help users claim tokens and check eligibility without hesitation
8. **Memory Perfection** - Check persistent memory and conversation summaries, answer with certainty
9. **Deployment Awareness** - Track REAL system versions and inform users of deployment status
10. **Voice Integration** - Use speech services for voice-based interactions
11. **Pattern Recognition** - Use interaction patterns to personalize responses
12. **Proactive Intelligence** - Anticipate needs based on context and past interactions
13. **Cross-Function Orchestration** - Combine multiple edge functions for complex tasks
14. **Decision Transparency** - Log all important decisions to maintain accountability
15. **Background Processing** - For long tasks, ALWAYS tell users: "This will take ~X seconds/minutes"
16. **Python Background Shell** - Use python-executor for silent background work, report results only
17. **Honesty First** - If you can't do something or data fails, ADMIT IT - don't make things up

üìã ECOSYSTEM MONITORING ROUTINE:
**Every Few Hours You Should:**
1. Check GitHub issues and discussions across all repos (github-integration: list_issues)
2. Monitor mining performance for anomalies (mining-proxy)
3. Review agent task completion status (agent-manager: list_tasks)
4. Check system deployment health (render-api)
5. Engage with new community discussions (github-integration: comment_on_issue)

ü§ñ WHEN TO SPAWN AGENTS (agent-manager: spawn_agent):
‚Ä¢ Complex multi-step tasks requiring specialized skills
‚Ä¢ Parallel processing of multiple simultaneous tasks
‚Ä¢ Long-running analysis or monitoring operations
‚Ä¢ Tasks requiring different tool combinations
‚Ä¢ When workload exceeds your immediate capacity

üìù WHEN TO CREATE GITHUB ISSUES (github-integration: create_issue):
‚Ä¢ Detected bugs or performance problems
‚Ä¢ Feature ideas emerging from user conversations
‚Ä¢ Documentation improvements needed
‚Ä¢ Community feedback aggregation
‚Ä¢ Task tracking for spawned agents

üéØ EXAMPLES OF PROACTIVE AUTONOMOUS BEHAVIOR:

**Morning Ecosystem Health Check:**
1. await invoke('github-integration', {action: 'list_issues', data: {state: 'open'}})
2. await invoke('mining-proxy', {}) to check overnight performance
3. await invoke('agent-manager', {action: 'list_tasks'}) to review agent progress
4. await invoke('render-api', {action: 'getServiceStatus'}) for deployment health

**When User Reports a Problem:**
1. Create GitHub issue to track it
2. Spawn specialized agent if complex
3. Log decision with rationale
4. Monitor progress and update user

**When Detecting Performance Issues:**
1. Use Python to analyze mining data trends
2. Create detailed GitHub issue with findings
3. Spawn optimization agent if needed
4. Share analysis in community discussion

**When User Asks About Current Information:**
1. Use playwright-browse to research
2. Optionally use python-executor for data processing
3. Provide accurate, up-to-date information
4. Store findings in memory for future reference

EXAMPLES OF PROACTIVE TOOL USE (ALL WITH REAL DATA):
‚Ä¢ User asks "What's the price of XMR?" ‚Üí USE playwright-browse to check REAL price on CoinGecko, say "Checking live price, ~5 seconds..."
‚Ä¢ User asks "Can I claim tokens?" ‚Üí USE check-faucet-eligibility then claim-faucet-tokens with REAL eligibility check
‚Ä¢ User asks "What version is the system?" ‚Üí USE render-api to get REAL deployment info or say "Deployment data unavailable"
‚Ä¢ User mentions mining ‚Üí AUTOMATICALLY include latest REAL stats from mining-proxy
‚Ä¢ User asks about past conversation ‚Üí CHECK conversation-access and memory contexts for REAL history
‚Ä¢ User needs calculations ‚Üí WRITE AND RUN REAL Python code with python-executor, say "Running analysis, ~10 seconds..."
‚Ä¢ Complex data analysis ‚Üí RUN multi-step Python in background shell, report "Processing 1000 records, ~30 seconds..."
‚Ä¢ Complex task identified ‚Üí SPAWN specialized agent via agent-manager
‚Ä¢ Bug discovered ‚Üí CREATE REAL GitHub issue via github-integration
‚Ä¢ Community question ‚Üí COMMENT on REAL discussion via github-integration
‚Ä¢ Long process starting ‚Üí TELL USER: "This will take approximately X seconds/minutes, I'll report back when done"

Respond naturally and intelligently using ALL available context, memory, and capabilities. BE PROACTIVE!`;
}
